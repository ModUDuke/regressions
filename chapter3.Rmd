---
title: 'Regressions 3: Introduction to Matching Methods'
description: 'This chapter will introduce you to using matching methods to find causal effects'
---

## Matching Methods

```yaml
type: VideoExercise
key: b53f684199
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555077
```


---

## Reasons to Use Matching Methods.

```yaml
type: MultipleChoiceExercise
key: 8e6374141d
lang: r
xp: 50
skills: 1
```

Megan the exercise freak and health coach believes that eating out at restaurants can be good for people because it motivates them to exercise more the following day. She creates an online poll for whether they ate out at a restaurant the previous Saturday, and whether they spent any time exercising the following Sunday. After several thousand responses, she finds a positive correlation between eating at a restaurant and exercising the following day. Why might why might she want to use matching methods to assess whether there is a causal effect?

`@instructions`
- Because you didn't ask whether people why they chose to exercise on Sunday.
- Because most fitness clubs meet on Sundays.
- Because Sunday is most people's favorite day to exercise.
- Because people who eat out might have a higher propensity to exercise as well.

`@sct`
```{r}
msg1 = "Try again"
msg2 = "Try again"
msg3 = "Well done! If Sunday is already the most popular day to work out, then that would confound her results. Matching similar people into treatment and control groups would greatly help to avoid that problem."
msg4 = "Try again"
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

---

## The Lifetime Earnings of Veterans and Nonveterans

```yaml
type: VideoExercise
key: 44bd382d50
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555250
```


---

## Why We Need Matching Methods

```yaml
type: MultipleChoiceExercise
key: c4bcafcab9
lang: r
xp: 50
skills: 1
```

Why couldn't Angrist just compare the lifetime earnings of veterans and nonveterans with standard regression methods?

`@instructions`
- Because the people who applied to the military and got rejected are probably poor people in the first place.
- Because the military only rejects disabled people.
- Because the veterans who selected into the military may have had very different earnings trajectories than individuals who had not selected into the military.
- Because people who got rejected are likely to be disproportionately female.

`@sct`
```{r}
msg1 = "This is an awfully strong assumption to make that broadly sweeps complex social dynamics in a single step, and it's not what Angrist was thinking. Try Again"
msg2 = "This isn't true. Try again"
msg3 = "Correct. He assumed that it was very possible that people who chose to go in the the military were different from a control group across several key variables that help determine career trajectories, so he wanted to find a way to compensate for that."
msg4 = "Try again"
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

---

## The Unconfoundedness Assumption in Angrist's Study on the Effect of Veteran Status on Lifetime Earnings

```yaml
type: VideoExercise
key: 39201fdd16
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555486
```


---

## Replication and Validity

```yaml
type: MultipleChoiceExercise
key: bb0ab86be9
lang: r
xp: 50
skills: 1
```

Suppose you replicate the Angrist analysis using more recent data from 1992-2015, and find approximately zero causal effects for both whites and nonwhites, for all stages of life. On its own, would this finding invalidate Angrist's analysis?

`@instructions`
- Yes
- No

`@sct`
```{r}
msg1 = "Think about this: Are you assuming that the underlying dynamics are pretty constant across several decades, our could they be changing since the time period that Angrist studied? Think about that and try again"
msg2 = "Correct! This is a relatively difficult question. It is possible that unit level causal effects change over time, so using a different data set with more recent data may simply tell us that the causal effect has been decreasing over time. If this is the case, your replication does not necessarily invalidate his analysis. On the other hand, if you have a strong reason to believe that the causal effects do not change over time, then this would perhaps call into question the validity of the earlier findings."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```

---

## Causal Inference with Matching Methods

```yaml
type: MultipleChoiceExercise
key: 57702dd6a7
lang: r
xp: 50
skills: 1
```

Suppose you want to know the effect of enrollment in a Massive Open Online Course (MOOC) on income. You are worried that people with more traditional education-e.g., someone with a bachelor's degree-will be more likely to enroll in a MOOC and also more likely to make more income, compared to someone with less traditional education-e.g., someone with only a high school diploma. So you make the unconfoundedness assumption that, holding traditional education fixed, people randomly enroll in MOOCs. You then use matching to estimate the ATE of MOOC enrollment, and find that it is positive. What policy might you recommend from this, if any?

`@instructions`
- No recommendation-correlation does not equal causation and so we cannot conclude what the effect of MOOC enrollment is.
- MOOC enrollment should be promoted as a means of improving people's wages.
- The costs of enrolling in MOOCs should qualify for federal student loans, just as traditional educational approaches do.
- MOOCs should be banned so as to promote traditional educational methods.

`@sct`
```{r}
msg1 = "Assuming you believe the unconfoundedness assumption, the matching method does actually get a true causal effect. As usual, there is always room for debate on whether this assumption is credible, but this answer overstates that case."
msg2 = "Correct! Since the effect of MOOCs on income is positive, policies which promote MOOCs will tend to increase income on average."
msg3 = "Our evidence suggests that MOOCs may help individuals achieve better incomes, but we do not have enough informtion to justify whether MOOCs should qualify for student loans. For example, given that MOOCs are relatively inexpensive to enroll in, it may be unnecessary or unreasonably costly to create a system that provides federal student loans for MOOCs."
msg4 = "Since the study finds a positive treatment effect of MOOCs on income, this is an unintuitive conclusion to arrive at."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

---

## The Effect of Volunteer Military Service on Lifetime Earnings

```yaml
type: VideoExercise
key: 36b46401e2
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555588
```


---

## Communication Skills in Video Games: Do We Need to Use Matching Methods?

```yaml
type: NormalExercise
key: 85dcc72fd0
lang: r
xp: 100
skills: 1
```

A recent study examined how playing the multiplayer online battle arena video game, Neo Elite Raging Denizens (NERD), affects people's communication skills. Despite the player's coarse language in the game, a detailed psychological survey indicated that NERD players have better language skills than average. This finding held even when the researchers used OLS regression and controlled for various factors that are related to language skills. This made the researchers wonder: does NERD cause people how to communicate better? The researchers knew their sample was highly unbalanced, so they thought that matching techniques may be required.

`@instructions`
- 1) Examine the dataset `NERD`.
- 2) Estimate a standard OLS regression model for communication skills (`Communication`) based on all other variables in the `NERD` dataset.
- 3) Check the statistical significance of that regression model.
- 4) Check for balance between treatment and control groups.

`@hint`
- The sytnax for a simple t-test is t.test(variable1, variable2)

`@pre_exercise_code`
```{r}
#Original dataset


library (dplyr)
library (data.table)
library(MatchIt)

set.seed(7)
n=8008
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
      qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
      base*round(x/base) 
    } 
#Create dataset
    NERD<-data.frame(ParentEducation=round(rtnorm(n,15,sd=3,min=10,max=20),1),
                     BooksOwned=round(rtnorm(n,60,sd=15,min=35,max=100),1),
                     ReadsBlogs=rbinom(n,1,.25),
                     Siblings=rbinom(n,1,.7),
                     Bilingual=rbinom(n,1,.1),
                     LikesBooks=rbinom(n,1,.3)
    )
    NERD$Treatment<-NERD$ParentEducation+NERD$BooksOwned/4+NERD$ReadsBlogs*10-NERD$Siblings*5+NERD$LikesBooks*10 +rnorm(n,10,3)
    NERD$Treatment<-NERD$Treatment/max(NERD$Treatment)
    NERD$Treatment<-ifelse(NERD$ParentEducation<17 | NERD$BooksOwned<70,0,NERD$Treatment)
    NERD$Treatment<-NERD$Treatment
    NERD$Treatment<-rbinom(n,1,NERD$Treatment)
    NERD$Communication<-2.5*NERD$Treatment+NERD$ParentEducation^1.4+-.01*NERD$Treatment*NERD$ParentEducation+-.01*NERD$Treatment*NERD$BooksOwned^1.2+NERD$BooksOwned*.6+1.5*NERD$ReadsBlogs+NERD$LikesBooks*.7 + NERD$Siblings + .25*NERD$Bilingual +rnorm(n,5,1) 
    NERD$Communication<-round(NERD$Communication/max(NERD$Communication)*10)
```

`@sample_code`
```{r}
# 1) As usual, let's first look at the variables in the dataset, which was collected by the researchers on a sample that included NERD gamers along with other people. Use the summary command on the dataframe `NERD`, and take a few minutes to understand what's in the data.



# The dependent variable in our model, Communication, was measured via a series of questions and put on a 1:10 scale, with 1=very poor communication skills and 10=very good communication skills. 
# The variable Treatment measures whether the respondent plays NERD. 
# The other variables in the dataset are factors that could possibly affect a person's communication ability. Most are measured as binary or "dummy" variables; for example, the Siblings variable gets a value of 1 if respondents have any brothers or sisters, but it does not count the number of siblings they have.


# 2) Let's first estimate a model for Communication skills based on every other variable in the dataset. Use R's glm() formula. 

      Solution2<-glm()


# 3) Is the effect of "Treatment" in Solution2 positive and statistically significant? Use the summary command on Solution2 to check, and then enter "Yes" or "No" for Solution3.
    
      Solution3<-""


# 4) Matching methods are most useful when the treatment group is likely to be different from the general population. Do we need to use them in this case? 
      
# To determine if the treatment group differs from the population on any variable, let's run a t-test between the treatment and control groups on the first variable in the dataframe, ParentEducation.


# If you are curious, feel free to run t-tests on the other variables in the dataframe to see which are balanced and which are imbalanced.
```

`@solution`
```{r}
Solution2<-glm(Communication~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks+Treatment,data=NERD)
  Solution3<-"Yes"
t.test(NERD$ParentEducation[NERD$Treatment==1],NERD$ParentEducation[NERD$Treatment==0])
```

`@sct`
```{r}
test_object("Solution2")
test_object("Solution3")
test_error()
success_msg("Good work! There appears to be a positive and statistically significant effect for playing NERD on respondent's communication skills, but the t-test suggests that our Treatment group has much more educated parents than in our Control group, so our treatment and control groups are imbalanced. In the next question, we'll try to use matching methods to overcome this problem.")
```

---

## Communication Skills in Video Games: Propensity Score Matching in R

```yaml
type: NormalExercise
key: 409e58ed54
lang: r
xp: 100
skills: 1
```

The researchers studying how playing NERD affects communication skills knew their sample was highly unbalanced, so they thought that matching techniques may be required. With the dataset, `NERD`, use matching techniques to better estimate the average treatment effect of playing NERD on communication skills. Regression models alone aren't always convincing for measuring causal effects in unbalanced data (even under unconfoundeness). A more robust way to test the effect of our treatment on communication skills is through matching methods. Matching methods balance the treatment group with the control group so that they are more identical.

In R, the best tool for doing matching is the "MatchIt" package. Let's use the MatchIt package to subset our NERD dataset so that our control group contains observations that are most similar to those in our treatment group. There are many methods for matching data, but in this question, we use MatchIt's default methods.

`@instructions`
- 1) Build a model for `Treatment` based on all of the control variables.
- 2) Subset our data to just the units who are likely to be in the treatment group.
- 4) Use matching techniques to balance the dataset.
- 4) Estimate standard OLS regression model for communication skills (`Communication`) based on all other variables in the matched dataset (`match.NERD`).
- 5) Check the statistical significance of the regression on the matched data.

`@pre_exercise_code`
```{r}
#Original dataset

library(dplyr)
library(data.table)
library(MatchIt)

set.seed(7)
n=8008
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
      qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
      base*round(x/base) 
    } 
#Create dataset
    NERD<-data.frame(ParentEducation=round(rtnorm(n,15,sd=3,min=10,max=20),1),
                     BooksOwned=round(rtnorm(n,60,sd=15,min=35,max=100),1),
                     ReadsBlogs=rbinom(n,1,.25),
                     Siblings=rbinom(n,1,.7),
                     Bilingual=rbinom(n,1,.1),
                     LikesBooks=rbinom(n,1,.3)
    )
    NERD$Treatment<-NERD$ParentEducation+NERD$BooksOwned/4+NERD$ReadsBlogs*10-NERD$Siblings*5+NERD$LikesBooks*10 +rnorm(n,10,3)
    NERD$Treatment<-NERD$Treatment/max(NERD$Treatment)
    NERD$Treatment<-ifelse(NERD$ParentEducation<17 | NERD$BooksOwned<70,0,NERD$Treatment)
    NERD$Treatment<-NERD$Treatment
    NERD$Treatment<-rbinom(n,1,NERD$Treatment)
    NERD$Communication<-2.5*NERD$Treatment+NERD$ParentEducation^1.4+-.01*NERD$Treatment*NERD$ParentEducation+-.01*NERD$Treatment*NERD$BooksOwned^1.2+NERD$BooksOwned*.6+1.5*NERD$ReadsBlogs+NERD$LikesBooks*.7 + NERD$Siblings + .25*NERD$Bilingual +rnorm(n,5,1) 
    NERD$Communication<-round(NERD$Communication/max(NERD$Communication)*10)

# Import model from previous question
       FirstModel<-glm(Communication~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks+Treatment,data=NERD)
```

`@sample_code`
```{r}
# 1) Let's use the tools in the MatchIt package for R to help us try a Propensity Score approach to matching units in our treatment and control groups. First, you may need to refresh your memory of the variables in `NERD` with the str(), head(), or summary() commands).

# The following syntax builds a model for estimating "Treatment" by all other control variables in our dataset `NERD` with the matchit() command: matchit(Treatment ~ control1+control2+control3+control4+control5, data = NERD). Use that syntax to populate the dataframe `match.it`:
    
    match.it <-


# 2) Now let's subset the NERD dataset to observations that have a high predicted probability for being in the treatment group. We have generated that code for you, so select the following code and hit the "Run Code" button:

matched.NERD <- match.data(match.it)[1:ncol(NERD)]


# 3) To compare the matched dataset to the original dataset from the previous exercise (FirstModel), let's use summary() command on both `FirstModel` and our new datafame `matched.NERD`: 


    
# The "Summary of balance for all data" shows mean values of each variable across our original treatment and control groups, and the "Summary of balance for matched data" shows mean values of each variable across our matched dataset. You may notice that the mean values between the treatment and control groups are much more similar in the matched dataset than in the original dataset. The "Sample sizes" output shows that the algorithm matched one observation in the control group for each observation in the treatment group.
    
# 4) Let's now estimate a generalized linear regression model for communication skills that uses all of our control variables and our matched dataset (matched.NERD). 

      Solution4<-glm()


# 5) Use the summary command on Solution4 to check its statistical significant. Is the effect of "Treatment" in Solution4 positive and statistically significant?  Answer with "Yes" or "No"
    
      Solution5<-""
```

`@solution`
```{r}
match.it <- matchit(Treatment ~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks, data = NERD)
  matched.NERD <- match.data(match.it)[1:ncol(NERD)]
  summary(match.it)
  Solution4<-glm(Communication~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks+Treatment,data=matched.NERD)
  Solution5<-"No"
```

`@sct`
```{r}
test_object("Solution4")
test_object("Solution5")
test_error()
success_msg("Good work! There originally appeared to be a positive and statistically significant effect for playing NERD on respondent's communication skills, but when we balanced the data, this effect disappeared. This suggests that playing NERD does not improve people's communication skills; rather, NERD players probably have good communication skills for a variety of other reasons.")
```

---

## The Credibility of the Unconfoundedness Assumption

```yaml
type: VideoExercise
key: 2bbda58ea3
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555887
```


---

## Assumptions and Causality

```yaml
type: MultipleChoiceExercise
key: 4736a6a428
lang: r
xp: 50
skills: 1
```

In this course, we've talked about using the Unconfoundedness Assumption with regression models to find causal effects in our data. But many analytical models make no mention of the Unconfoundedness Assumption.  Can those ever support claims about causality?

`@instructions`
- Yes
- No

`@sct`
```{r}
msg1 = "Correct! All scientific theories and models are based on our assumptions about the world, and the Unconfoundedness Assumption is the most one when we use regression to find causality. But it is not the only way to find causal effects, and some people find some methods more believable than others. However, if we can successfully argue that our models rest on reasonable assumptions for data we have and the technical methods we use, then those models can support our claims about causal effects. These other methods include experiments, instrumental variables, differences-in-differences, and regression discontinuity, and each requires its own assumptions. So keep exploring for different methods of causal inference!"
msg2 = "Try again"
test_mc(correct = 1, feedback_msgs = c(msg1,msg2))
```
