---
title: 'Regressions 3: Introduction to Matching Methods'
description: 'This chapter will introduce you to using matching methods to find causal effects'
---

## Matching Methods

```yaml
type: VideoExercise
key: b53f684199
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555077
```


---

## Should Megan Use Matching Methods With Her Survey?

```yaml
type: MultipleChoiceExercise
key: 8e6374141d
lang: r
xp: 50
skills: 1
```

Megan the exercise freak and health coach believes that eating out at restaurants can be good for people because it motivates them to exercise more the following day. She creates an online survey for whether they ate out at a restaurant the previous Saturday, and whether they spent any time exercising the following Sunday. After several thousand responses, she finds a positive correlation between eating at a restaurant and exercising the following day. Why might why might she want to use matching methods to assess whether there is a causal effect?

`@instructions`
- She needs to match people to run a regression
- She doesn't: if there is a correlation between the two variables, then she has found her effect
- She needs to create treatment and control groups to find a causal effect.
- Because people who eat out might have a higher propensity to exercise as well.

`@sct`
```{r}
msg1 = "Matching methods are not requirements for running a regression. Try again."
msg2 = "Remember, correlation does not mean causation, and Megan is looking for a causal effect. Try again."
msg3 = "Well done! Megan can find pairs of respondents who seem identical except one ate a restaurant on Saturday and one did not."
msg4 = "This might be a problem, but it's a general confounder to worry about and is not specific to matching methods. Try again."
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```


---

## Can Your Survey Design Affect Your Matching Methods?

```yaml
type: MultipleChoiceExercise
key: 8e6374141d
lang: r
xp: 50
skills: 1
```
So Megan has run her social media survey over a Saturday and a Sunday, has collected several thousand responses, and you've convinced her that she should use matching methods to find out if her correlation is actually a causal effect. What might be survey design issues that could hurt her attempts at using matching methods to generate a convincing causal effect of going to a restaurant on exercise?

`@instructions`
- A) If she made some of her questions optional, she may have a lot of missing values in her data
- B) Because it's on social media, some responses will be tainted by peer pressure
- C) If she doesn't define what she means by exercise or eating, then people might cheat with their answers
- D) A and C
- All of the above

`@sct`
```{r}
msg1 = "If she has too much missing data, she won't be able to get good matches, but there are other issues too. Try again."
msg2 = "Yes, it may be nearly impossible for Megan to factor out all peer pressure from her social media survey results, but that's not the only valid issue listed here. Try again."
msg3 = "This would mean her causal effect is fairly meaningless because we don't know what everyone meant by exercise or eating, but there is more to consider. Try again."
msg4 = "There is something else beside A and C that might be a problem. Try again."
msg5 = "Well done! There are lots of issues to consider when designing a survey, and even more if you are aiming to calculate a causal effect. While matching methods are useful for generating treatment and control groups from complex data like survey data, you'll need lots of properly written questions with clear measurements to help you find good matches in your matching method."
test_mc(correct = 5, feedback_msgs = c(msg1,msg2,msg3,msg4,msg5))
```


---

## Problems with Matching Methods When Comparing Individuals?

```yaml
type: MultipleChoiceExercise
key: 8e6374141d
lang: r
xp: 50
skills: 1
```

Let's say that you've convinced Megan to add a couple of questions to her survey, and she runs it again the following weekend in order to get better data that allows her to use matching methods. What might be a unit-level issue that could hurt her attempts at matching?

`@instructions`
- She didn't ask enough survey questions, so she doesn't have enough variables to make good matches between respondents. 
- She used text fields for answers, and there might be too many differences between respondents to make good matches.
- She asked similar questions in different ways, and it's hard to know which responses to trust most when matching.
- All of the above.
- None of the above.


`@sct`
```{r}
msg1 = "This is definitely an issue, but it's not the only one listed. Try again."
msg2 = "This is definitely an issue, and it's tricky to generate quantified matches based on qualitative data, but that's not the only problem. Try again."
msg3 = "This can be an issue: if someone's response changes from 2 to 8 just with a reworded question, which number do we base our match on? But there are more issues than this, so try again. "
msg4 = "Well done! You should make sure that you have enough clear variables with consistent measurements before you try creating matches that create comparable and well-defined treatment and control groups."
msg5 = "There is at least one clear issue listed that might interfere with matching methods. Try again."
test_mc(correct = 4, feedback_msgs = c(msg1,msg2,msg3,msg4,msg5))
```


---

## The Lifetime Earnings of Veterans and Nonveterans

```yaml
type: VideoExercise
key: 44bd382d50
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555250
```


---

## Why We Need Matching Methods

```yaml
type: MultipleChoiceExercise
key: c4bcafcab9
lang: r
xp: 50
skills: 1
```

Why couldn't Angrist just compare the lifetime earnings of veterans and nonveterans with standard regression methods?

`@instructions`
- Because the people who applied to the military and got rejected are probably poor people in the first place.
- Because the military only rejects disabled people.
- Because the veterans who selected into the military may have had very different earnings trajectories than individuals who had not selected into the military.
- Because people who got rejected are likely to be disproportionately female.

`@sct`
```{r}
msg1 = "This is an awfully strong assumption to make that broadly sweeps complex social dynamics in a single step, and it's not what Angrist was thinking. Try Again"
msg2 = "This isn't true. Try again"
msg3 = "Correct. He assumed that it was very possible that people who chose to go in the the military were different from a control group across several key variables that help determine career trajectories, so he wanted to find a way to compensate for that."
msg4 = "Try again"
test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

---

## The Unconfoundedness Assumption in Angrist's Study on the Effect of Veteran Status on Lifetime Earnings

```yaml
type: VideoExercise
key: 39201fdd16
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555486
```


---

## Replication and Validity

```yaml
type: MultipleChoiceExercise
key: bb0ab86be9
lang: r
xp: 50
skills: 1
```

Suppose you replicate the Angrist analysis using more recent data from 1992-2015, and find approximately zero causal effects for both whites and nonwhites, for all stages of life. On its own, would this finding invalidate Angrist's analysis?

`@instructions`
- Yes
- No

`@sct`
```{r}
msg1 = "Think about this: Are you assuming that the underlying dynamics are pretty constant across several decades, our could they be changing since the time period that Angrist studied? Think about that and try again"
msg2 = "Correct! This is a relatively difficult question. It is possible that unit level causal effects change over time, so using a different data set with more recent data may simply tell us that the causal effect has been decreasing over time. If this is the case, your replication does not necessarily invalidate his analysis. On the other hand, if you have a strong reason to believe that the causal effects do not change over time, then this would perhaps call into question the validity of the earlier findings."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2))
```

---

## Causal Inference with Matching Methods

```yaml
type: MultipleChoiceExercise
key: 57702dd6a7
lang: r
xp: 50
skills: 1
```

Suppose you want to know the effect of enrollment in a Massive Open Online Course (MOOC) on income. You are worried that people with more traditional education-e.g., someone with a bachelor's degree-will be more likely to enroll in a MOOC and also more likely to make more income, compared to someone with less traditional education-e.g., someone with only a high school diploma. So you make the unconfoundedness assumption that, holding traditional education fixed, people randomly enroll in MOOCs. You then use matching to estimate the ATE of MOOC enrollment, and find that it is positive. What policy might you recommend from this, if any?

`@instructions`
- No recommendation-correlation does not equal causation and so we cannot conclude what the effect of MOOC enrollment is.
- MOOC enrollment should be promoted as a means of improving people's wages.
- The costs of enrolling in MOOCs should qualify for federal student loans, just as traditional educational approaches do.
- MOOCs should be banned so as to promote traditional educational methods.

`@sct`
```{r}
msg1 = "Assuming you believe the unconfoundedness assumption, the matching method does actually get a true causal effect. As usual, there is always room for debate on whether this assumption is credible, but this answer overstates that case."
msg2 = "Correct! Since the effect of MOOCs on income is positive, policies which promote MOOCs will tend to increase income on average."
msg3 = "Our evidence suggests that MOOCs may help individuals achieve better incomes, but we do not have enough informtion to justify whether MOOCs should qualify for student loans. For example, given that MOOCs are relatively inexpensive to enroll in, it may be unnecessary or unreasonably costly to create a system that provides federal student loans for MOOCs."
msg4 = "Since the study finds a positive treatment effect of MOOCs on income, this is an unintuitive conclusion to arrive at."
test_mc(correct = 2, feedback_msgs = c(msg1,msg2,msg3,msg4))
```

---

## The Effect of Volunteer Military Service on Lifetime Earnings

```yaml
type: VideoExercise
key: 36b46401e2
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555588
```

---
## Let’s Code: Communication Skills in Video Games

```yaml
type: VideoExercise
key: 5c9d6dd3fc
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/293196315
```


---

## Communication Skills in Video Games: Do We Need to Use Matching Methods?

```yaml
type: NormalExercise
key: 85dcc72fd0
lang: r
xp: 100
skills: 1
```

A recent study examined how playing the multiplayer online battle arena video game, Neo Elite Raging Denizens (NERD), affects people's communication skills. Despite the player's coarse language in the game, a detailed psychological survey indicated that NERD players have better language skills than average. This finding held even when the researchers used OLS regression and controlled for various factors that are related to language skills. This made the researchers wonder: does NERD cause people how to communicate better? The researchers knew their sample was highly unbalanced, so they thought that matching techniques may be required.

`@instructions`
- 1) Examine the dataset `NERD`.
- 2) Estimate a standard OLS regression model for communication skills (`Communication`) based on all other variables in the `NERD` dataset.
- 3) Check the statistical significance of that regression model.
- 4) Check for balance between treatment and control groups.

`@hint`
- The sytnax for a simple t-test is t.test(variable1, variable2)

`@pre_exercise_code`
```{r}
#Original dataset


library(dplyr)
library(data.table)
library(MatchIt)

set.seed(7)
n=8008
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
      qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
      base*round(x/base) 
    } 
#Create dataset
    NERD<-data.frame(ParentEducation=round(rtnorm(n,15,sd=3,min=10,max=20),1),
                     BooksOwned=round(rtnorm(n,60,sd=15,min=35,max=100),1),
                     ReadsBlogs=rbinom(n,1,.25),
                     Siblings=rbinom(n,1,.7),
                     Bilingual=rbinom(n,1,.1),
                     LikesBooks=rbinom(n,1,.3)
    )
    NERD$Treatment<-NERD$ParentEducation+NERD$BooksOwned/4+NERD$ReadsBlogs*10-NERD$Siblings*5+NERD$LikesBooks*10 +rnorm(n,10,3)
    NERD$Treatment<-NERD$Treatment/max(NERD$Treatment)
    NERD$Treatment<-ifelse(NERD$ParentEducation<17 | NERD$BooksOwned<70,0,NERD$Treatment)
    NERD$Treatment<-NERD$Treatment
    NERD$Treatment<-rbinom(n,1,NERD$Treatment)
    NERD$Communication<-2.5*NERD$Treatment+NERD$ParentEducation^1.4+-.01*NERD$Treatment*NERD$ParentEducation+-.01*NERD$Treatment*NERD$BooksOwned^1.2+NERD$BooksOwned*.6+1.5*NERD$ReadsBlogs+NERD$LikesBooks*.7 + NERD$Siblings + .25*NERD$Bilingual +rnorm(n,5,1) 
    NERD$Communication<-round(NERD$Communication/max(NERD$Communication)*10)
```

`@sample_code`
```{r}
# 1) As usual, let's first look at the variables in the dataset, which was collected by the researchers on a sample that included NERD gamers along with other people. Use the summary command on the dataframe `NERD`, and take a few minutes to understand what's in the data.


# Notes:
# The dependent variable in our model, Communication, was measured via a series of questions and put on a 1:10 scale, with 1=very poor communication skills and 10=very good communication skills. 
# The variable Treatment measures whether the respondent plays NERD. 
# The other variables in the dataset are factors that could possibly affect a person's communication ability. Most are measured as binary or "dummy" variables; for example, the Siblings variable gets a value of 1 if respondents have any brothers or sisters, but it does not count the number of siblings they have.


# 2) Let's first estimate a model for Communication skills based on every other variable in the dataset. Use R's glm() formula. 

      Solution2<-glm()


# 3) Is the effect of "Treatment" in Solution2 positive and statistically significant? Use the summary command on Solution2 to check, and then enter "Yes" or "No" for Solution3.
    
      Solution3<-""


# 4) Matching methods are most useful when the treatment group is likely to be different from the control group in ways that are unrelated to our outcome. Do we need to use them in this case? To determine if the treatment group differs from the population on any variable, let's run a t-test between the treatment and control groups on the first variable in the dataframe, ParentEducation. As a reminder, the syntax for a simple t-test is t.test(variable1, variable2)

t.test()

# If you are curious, feel free to run t-tests on the other variables in the dataframe to see which are balanced and which are imbalanced.
```

`@solution`
```{r}
Solution2<-glm(Communication~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks+Treatment,data=NERD)
  Solution3<-"Yes"
t.test(NERD$ParentEducation[NERD$Treatment==1],NERD$ParentEducation[NERD$Treatment==0])
```

`@sct`
```{r}
test_object("Solution2")
test_object("Solution3")
test_error()
success_msg("Good work! There appears to be a positive and statistically significant effect for playing NERD on respondent's communication skills, but the t-test suggests that our Treatment group has much more educated parents than in our Control group, so our treatment and control groups are imbalanced. In the next question, we'll try to use matching methods to overcome this problem.")
```

---

## Communication Skills in Video Games: Propensity Score Matching in R

```yaml
type: NormalExercise
key: 409e58ed54
lang: r
xp: 100
skills: 1
```

The researchers studying how playing NERD affects communication skills knew their sample was highly unbalanced, so they thought that matching techniques may be required. With the dataset, `NERD`, use matching techniques to better estimate the average treatment effect of playing NERD on communication skills. Regression models alone aren't always convincing for measuring causal effects in unbalanced data (even under unconfoundeness). A more robust way to test the effect of our treatment on communication skills is through matching methods. Matching methods balance the treatment group with the control group so that they are more identical.

In R, the best tool for doing matching is the "MatchIt" package. Let's use the MatchIt package to subset our NERD dataset so that our control group contains observations that are most similar to those in our treatment group. There are many methods for matching data, but in this question, we use MatchIt's default methods.

`@instructions`
- 1) Build a model for `Treatment` based on all of the control variables.
- 2) Subset our data to just the units who are likely to be in the treatment group.
- 3) Use matching techniques to balance the dataset.
- 4) Estimate standard OLS regression model for communication skills (`Communication`) based on all other variables in the matched dataset (`match.NERD`).
- 5) Check the statistical significance of the regression on the matched data.

`@hint`


`@pre_exercise_code`
```{r}
#Original dataset

library(dplyr)
library(data.table)
library(MatchIt)

set.seed(7)
n=8008
#Create rnorm function that allows for min and max
    rtnorm <- function(n, mean, sd, min = -Inf, max = Inf){
      qnorm(runif(n, pnorm(min, mean, sd), pnorm(max, mean, sd)), mean, sd)
    }
#Create rounding function that allows to round to numbers above 1
    mround <- function(x,base){ 
      base*round(x/base) 
    } 
#Create dataset
    NERD<-data.frame(ParentEducation=round(rtnorm(n,15,sd=3,min=10,max=20),1),
                     BooksOwned=round(rtnorm(n,60,sd=15,min=35,max=100),1),
                     ReadsBlogs=rbinom(n,1,.25),
                     Siblings=rbinom(n,1,.7),
                     Bilingual=rbinom(n,1,.1),
                     LikesBooks=rbinom(n,1,.3)
    )
    NERD$Treatment<-NERD$ParentEducation+NERD$BooksOwned/4+NERD$ReadsBlogs*10-NERD$Siblings*5+NERD$LikesBooks*10 +rnorm(n,10,3)
    NERD$Treatment<-NERD$Treatment/max(NERD$Treatment)
    NERD$Treatment<-ifelse(NERD$ParentEducation<17 | NERD$BooksOwned<70,0,NERD$Treatment)
    NERD$Treatment<-NERD$Treatment
    NERD$Treatment<-rbinom(n,1,NERD$Treatment)
    NERD$Communication<-2.5*NERD$Treatment+NERD$ParentEducation^1.4+-.01*NERD$Treatment*NERD$ParentEducation+-.01*NERD$Treatment*NERD$BooksOwned^1.2+NERD$BooksOwned*.6+1.5*NERD$ReadsBlogs+NERD$LikesBooks*.7 + NERD$Siblings + .25*NERD$Bilingual +rnorm(n,5,1) 
    NERD$Communication<-round(NERD$Communication/max(NERD$Communication)*10)

# Import model from previous question
       FirstModel<-glm(Communication~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks+Treatment,data=NERD)
```

`@sample_code`
```{r}
# Note: You may want to refresh your memory of the variables in `NERD` with the str(), head(), or summary() commands).

# 1) Let's use the tools in the MatchIt package for R to help us try a Propensity Score approach to matching units in our treatment and control groups. The following syntax builds a model for estimating "Treatment" by all other control variables in our dataset `NERD` with the matchit() command: matchit(Treatment ~ control1 + control2 + control3 + control4 + control5, data = NERD). Use that syntax to populate the dataframe `match.it`:
    
    match.it <-


# 2) Now let's subset the NERD dataset to observations that have a high predicted probability for being in the treatment group. We have generated that code for you, so select the following code and hit the "Run Code" button:

	matched.NERD <- match.data(match.it)[1:ncol(NERD)]

# 3) Let's use the summary() command on our new datafame `matched.NERD`: 

	summary()
    
# The "Summary of balance for all data" shows mean values of each variable across our original treatment and control groups, and the "Summary of balance for matched data" shows mean values of each variable across our matched dataset. You may notice that the mean values for most variables between the treatment and control groups are now pretty similar. The "Sample sizes" output shows that the algorithm matched one observation in the control group for each observation in the treatment group.
    
# 4) Let's now estimate a generalized linear regression model for communication skills that uses all of our control variables and our matched dataset (matched.NERD). 

      Solution4<-glm()

# 5) Use the summary command on Solution4 to check its statistical significant. Is the effect of "Treatment" in Solution4 positive and statistically significant?  Answer with "Yes" or "No"
    
	summary(Solution4)
    Solution5<-""

#Note: For the sake of comparison, the syntax below shows us our regression results when our data were unmatched. Notice that the treatment effect was positive.
	summary(FirstModel)
```

`@solution`
```{r}
match.it <- matchit(Treatment ~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks, data = NERD)
  matched.NERD <- match.data(match.it)[1:ncol(NERD)]
  summary(match.it)
  Solution4<-glm(Communication~ ParentEducation+BooksOwned+ReadsBlogs+Siblings+Bilingual+LikesBooks+Treatment,data=matched.NERD)
  summary(Solution4)
  Solution5<-"No"
```

`@sct`
```{r}
test_object("Solution4")
test_object("Solution5")
test_error()
success_msg("Good work! In our unmatched model, the treatment effect (playing NERD) appeared to have a positive and statistically significant effect on respondent's communication skills. However, when we balanced the data, this effect disappeared. It turns out that the original treatment effect was spurious; it resulted from our biased sample of people who play NERD. When we compared people who played NERD to relatively similar people who don't play nerd, this treatment effect disappeared. That means that playing NERD does not improve people's communication skills; rather, NERD players have good communication skills because the people who are attracted to NERD tend to have good communication skills. Or in other words, this association results from a selection bias - not from a treatment effect.")
```

---

## The Credibility of the Unconfoundedness Assumption

```yaml
type: VideoExercise
key: 2bbda58ea3
lang: r
xp: 50
skills: 1
video_link: //player.vimeo.com/video/217555887
```


---

## Assumptions and Causality

```yaml
type: MultipleChoiceExercise
key: 4736a6a428
lang: r
xp: 50
skills: 1
```

In this course, we've talked about using the Unconfoundedness Assumption with regression models to find causal effects in our data. But many analytical models make no mention of the Unconfoundedness Assumption.  Can those ever support claims about causality?

`@instructions`
- Yes
- No

`@sct`
```{r}
msg1 = "Correct! All scientific theories and models are based on our assumptions about the world, and the Unconfoundedness Assumption is the most one when we use regression to find causality. But it is not the only way to find causal effects, and some people find some methods more believable than others. However, if we can successfully argue that our models rest on reasonable assumptions for data we have and the technical methods we use, then those models can support our claims about causal effects. These other methods include experiments, instrumental variables, differences-in-differences, and regression discontinuity, and each requires its own assumptions. So keep exploring for different methods of causal inference!"
msg2 = "Try again"
test_mc(correct = 1, feedback_msgs = c(msg1,msg2))
```
